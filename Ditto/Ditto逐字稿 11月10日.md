# 开场

今天我要分享的论文名字叫《Deep Entity Matching with Pre-Trained Language Models》，本文于2020年4月1日在arxiv上发表初版，并被收录于2021的VLDB会议中。主要作者是来自于Megagon实验室的Yuliang Li、Jinfeng Li、Suhara三人。本篇文章的特殊意义在于本文是首个公开发表的将预训练语言模型应用到实体匹配领域的论文，并且相比之前的sota取得了非常不错的效果。

# Megagon Labs简介

Megagon Labs主页：https://megagon.ai/

Megagon Labs是Recruit公司的创新中心，下图展示了这个lab的主要研发产品，可以看出这个lab的主要研究方向涉及数据库、自然语言处理和知识管理等方向。其中Ditto便是我们今天要介绍的模型。

# 目录

本次分享主要分为六个部分：背景、相关工作、结论及技术要点、模型、实验，还有对于本文的评价。

# 背景

首先来看背景部分。

（切ppt，进入1.1）

实体匹配主要是用来分辨两个实体或者字符串是否有着相同的语义，比如“百度有限公司”和“百度科技有限公司”、“5%”和“5.00%”诸如此类的实体。在数据库领域表现为在两个数据表合并的时候将重复数据进行合并，是DB for AI领域的一项重要技术。实体匹配技术在知识图谱领域也有着相似的应用，比如实体统一(Entity Resolution)技术、实体消歧(Entity Disambiguation)技术。

（切ppt，进入1.2）

一般情况下，实体匹配模型的输入为两个实体条目的集合，可以是table、JSON文件、文本文件等。实体匹配模型会输出一个集合，包含了所有有着相同语义或者说指向同一实体的实体对。下方是一个实体匹配问题实例，图中展示了两张来自不同数据源的产品信息记录表，本文想要找到指向同一真实世界产品的记录。

（切ppt，进入1.3）

实体匹配主要过程分为两步，分块和匹配。

分块的目标是减少明显不匹配的侯选对数量，减少计算量，通常分块规则是灵活规定的。比如在文中给出的例子里，如果不进行分块，本文需要对$3 \times 3=9$对实体进行匹配。而如果本文规定每对实体必须在“title”这一列的值中有至少一个相同的token才算作一个候选实体对，如图中三种颜色的方框所示，这里规定的一个token就是一个单词。本文便能够将候选实体对由9对减少到3对。匹配过程中常用的方法主要有基于规则的匹配、机器学习和深度学习等。

目前来说，实体匹配对于现有技术仍然有很大的挑战性，主要体现在对于语义和语法的理解，也就是怎么样让机器正确的认识实体中本质的含义。正确匹配候选对需要大量的语言理解和特定领域的知识。

（切ppt，进入2）

# 相关工作

下面介绍一下在该领域的一些相关工作。

（切ppt，进入2.1）

早在1959年，由Newcombe发表在Science上的《Automatic linkage of vital records》就提出了识别数据库中重复记录的问题，并把这项技术命名为record linkage（记录链接），记录链接起源于公共卫生领域，当时使用姓名、出生日期和其他信息将单个患者的档案汇总在一起。后来，Fellegi 和 Sunter在1969年发表了《A theory for record linkage》提出了record linkage的正式数学模型，被称为Fellegi-Sunter 模型，他们的理论证明了 Newcombe 使用的决策规则的最优性，并引入了多种直接从被匹配文件中估计关键匹配概率（参数）的方法，这些模型和方法也影响到了机器学习在实体匹配领域的发展。直到1999年，Winkler发表了《The state of record linkage and current research problems》 提出使用基于实体匹配的思想来获得最佳匹配规则。

（切ppt，进入2.2）

实体匹配技术可以大致分为三种：1.基于规则的实体匹配方法 2.基于机器学习的实体匹配方法 3.基于深度学习的实体匹配方法。基于规则的方法是通过声明实体匹配规则进行匹配，基于机器学习的方法是将实体匹配视为分类问题，使用聚类算法、SVM、马尔科夫逻辑和决策树等方法进行匹配。基于深度学习的实体匹配方法则更多通过LSTM神经网络或者现代的预训练模型，类似于Bert和Transformer，在模型上进行微调解决问题。

（切ppt，进入2.3）

基于规则的实体匹配代表性文献主要有三篇文献，并且这些方法通常假设 EM 规则是由领域专家给出的，这在真正的实践过程中还是难以实现的。更多的还是关注后面两种方法：基于机器学习的实体匹配和基于深度学习的实体匹配。

（切ppt，进入2.4）

基于机器学习的实体匹配。大多数当前的解决方案是 Fellegi-Sunter 模型的变体，其中实体匹配被视为分类问题。这些方法包括基于 SVM 的方法 （ Fellegi-Sunter）、基于决策树的解决方案、基于聚类的技术和基于马尔可夫逻辑的模型 。在Cohen和Richman撰写的《 Learning to Match and Cluster Large High-Dimensional Data Sets For Data Integration 》中定义了术语“entity-name matching”，可能是最早出现的类似于“entity matching”的定义。2016年，Himabindu等曾在文章中质疑机器学习的可解释性。说:“Many applications require that models be interpretable, meaning that humans can easily understand the information they contain.”

（切ppt，进入2.5）

深度学习火了之后，也很快速的被应用到了实体匹配领域，2018年发布的DeepMatcher将深度学习引入了实体匹配，DeepMatcher改动了RNN 架构来聚合属性值，然后比较或者对齐属性的聚合表示。同年，Muhammad等人提出了基于LSTM神经网络和GloVe等词嵌入技术的Deeper模型。DeepER 还提出了一种分块技术，用 LSTM 的输出来表示每个条目。2019年，Auto-EM提出将迁移学习应用到实体匹配领域，即一次训练之后不用再为每个别的实体匹配任务单独进行训练。2021年提出的Ditto使用了预训练模型，预训练模型相比传统模型的一个优势就是能够根据上下文调整词向量的值，而传统模型不能。2022年由中国人民大学范举带领的团队发表了《Domain Adaptation for Deep Entity Resolution》，也借助了迁移学习，提出了DADER模型。

（切ppt，进入3）

# 结论及技术要点

下面在介绍模型之前介绍一下本文的结论和技术要点

（切ppt，进入小标题3）

为了解决匹配结果准确性低的问题，本文提出了Ditto，一个基于预训练模型的实体匹配系统。后面在实验部分会提到，Ditto支持四种预训练模型。主要技术内容包括：

1.将输入的候选对进行序列化，将其转化为序列对分类问题再进行处理。

2.使用预训练模型，在大型文本语料库上进行训练。预训练模型包括像 BERT,、DistilBERT等。

3.对采用的模型进行微调，使其符合训练目标：正确判断候选对是否指向同一实体。

4.提出三种优化技术，提高Ditto匹配能力：

- 注入领域知识(Domain Knowledge, DK)
- 长字符串摘要(Summarize, SU)
- 数据增强(Data Augmentation, DA)

Ditto在相同的数据集上面测得的F1分数比之前的sota都要高，最高的一项能多31%。

（切ppt，进入4）

# 模型

下面介绍一下本文提出的模型

（切ppt，进入4.1）

模型的输入是两个数据表，将其放入blocker中进行分块，可以得到候选实体对的集合。将候选对集合输入进Ditto进行序列化，再经过领域知识注入、长字符串摘要等过程之后，将候选对一对一对的输入进matcher，最终得到一组各自相同的实体对集合$(e,e^{\prime})$，其中$e = (attr_i, val_i)$。$attr_i$表示属性名称，$val_i$表示属性值。

（切ppt，进入4.2）

首先对序列化技术进行讲解，对输入数据进行序列化的目的是为了规范数据格式，让模型更方便的进行数据识别。在本文中，对于每一个实体$e=\left\{\left(\operatorname{attr}_i, \operatorname{val}_i\right)\right\}_{1 \leq i \leq k}$，通过添加两个特殊标记：Column标记与Value标记将该实体进行序列化。一般在数据表合并的任务中，会在列名前打上Column标记，会在该列对应的属性值前打上Value标记，如下图所示。这行记录是在第1.2的示例图中第二个表的第二行实体。将其序列化之后就转变为右边的形式。

将一对候选对中的两项分别进行序列化之后，再通过特殊标记Classification和Separator进行连接，便可以得到序列化之后的实体对序列。值得一提的是，Ditto的序列化允许候选对中的两项是异质的，也不要求在进入matcher之前对各项属性进行匹配或者对齐，与其他EM系统有着明显的不同。在最下面的两个记录展示了“异质”的例子，这两个记录分别来自沃尔玛和亚马逊，两个记录的结构完全不同，但是指向的确实是同一件商品。

像在DeepMatcher模型中的输入是两个数据表，这就需要你保证两个实体的列名和列的数量完全一致，但是Ditto中的matcher输入的是两个字符串，对列名和列的数量不做要求。

（切ppt，进入4.3）

对预训练语言模型（Language Model，LM）进行微调主要目标是让模型训练更具有针对性，本文中使用由匹配和非匹配实体对组成的带标签训练数据集为 EM 任务微调预训练的 LM：

- 在语言模型的最后一层之后，添加特定任务层。本模型添加了一层全连接层与用于二分类的Softmax层，用于根据生成的嵌入判断两个数据项是否指向同一实体。
- 用预训练的模型参数初始化微调后的网络。
- 在训练集上训练微调后的网络，直至收敛。

预训练 LM 的一个特定优势在于，它比传统的词嵌入技术（如 word2vec、GloVe 或 FastText）更好地学习词的语义，因为Transformer生成的词向量是高度上下文化的。

（切ppt，进入4.3）

左图展示了匹配器matcher的基本结构，最底下是序列化后的实体对，中间是使用的预训练模型。预训练模型有多种选择，Ditto目前支持4中预训练模型：BERT、DistilBERT、RoBERTa 和 XLNet。

（切ppt，进入4.4）

正如之前描述的那样，基本的Ditto版本只利用预先训练好的LM，已经超过了许多现有EM技术的表现。在这里，本文描述了三种优化技术，促进Ditto进一步更加努力的训练，以作出匹配决策。

本文主要介绍了三种优化措施：

1. 领域知识注入

   预处理输入序列的过程中将领域知识注入Ditto，以强调哪些信息是关键信息。主要包含两种方法：识别片段类型(Span Typing)和片段规范化(Span Normalization)。

2. 长字符串摘要

   当候选项中的值是一个极长的字符串时，语言模型会难以分辨出字符串中的关键信息，并且基于Transformer的预训练过程对输入字符串长度有限制。

3. 数据增强

   数据增强(DA)技术可以增加训练数据数目，帮助EM模型 “更努力 ”地学习，有助于增加模型对脏数据的鲁棒性。

接下来一次介绍这三种优化措施，首先是领域知识注入。

（切ppt，进入4.5.1）

领域知识注入通过预处理输入序列（即序列化数据条目）将领域知识注入 Ditto，来告诉模型哪些信息可能很重要。这么做的原因是，当人类工作者考虑两个数据条目匹配与否时，通常会在做出最终决定前寻找包含关键信息的文本片段。除了这个方法以外，使用深度学习也可以达到要求的预期，但需要大量数据进行支持。

领域知识注入可以细分为两种方法：Span Typing和Span Normalization。	

Span Typing是一种给片段打标记的方法，Ditto可以通过这个标记来区分片段的类型，防止无意义的将不同类型的两个片段进行比较。比如将街道号和年份或者是产品id进行比较。下表总结了本文的基准数据集中匹配三种类型的实体时将关注的主要片段类型。

（切ppt，进入4.5.1）

开发人员指定一种识别器可以给片段打上标记，定义如本页公式所示。recognizer接收的输入为一串待标记的文本v，返回的是一个由三元组构成的列表。s表示开始位置，t表示结束位置，type表示片段类型。给片段打标记涉及到命名实体识别技术（Named-Entity Recognition,NER），Ditto利用Spacy，一个开源的实体识别模型，来识别已知的类型（例如product,people,publication等），并使用正则表达式来识别特定的类型。

类型被识别后，原始文本 v 被新文本替换，其中插入了特殊标记以反映标签的类型。比如在文章给出的例子中，待标记的文本是一个电话号码，这里给电话号码的后四位打上了Last标记，也因为tokenization的关系，有一些空格插入了进来。

片段类型标记之后还有一个功能就是对齐，如果两个片段具有相同类型，Ditto会觉得它们会有相同的标记位置，因此会将标记对齐以进行匹配。比如有这么一串文本
$$
\text{..246- [LAST] 6453 [/LAST] .. [SEP] .. [LAST] 0000 [/LAST]..}
$$
当模型看到两个带有 [LAST] 特殊标记的编码序列时，它可能会将“6453”与“0000”对齐以进行匹配。

（切ppt，进入4.5.1）

片段规范化可以将在语法上不同但语义的片段，改写成为相同的字符串，这样一来它们就会生成相近的词向量，Ditto就更容易识别这两个片段是相同的。本文通过指定一套规则对片段进行重写，实现片段规范化。该规范由一套函数组成，该函数首先识别引起关注的片段，然后依据重写规则对其进行重写。

Ditto 包含许多数字的重写规则，包括将所有浮点数四舍五入到小数点后 2 位以及从整数中删除所有逗号的规则，例如，本页中的“2,020”→“2020”。

（切ppt，进入4.5.2）

接下来讲解一下长字符串摘要技术，本质上该技术是对长字符串的特征提取。

长字符串对模型训练有许多不利影响：

- 当候选项中的值是一个极长的字符串时，LM会难以分辨出字符串中的关键信息。
- 基于Transformer的预训练模型对输入字符串长度有限制，比如在bert中的输入最多能有512个sub-word token。
- 传统的处理方式为直接截断字符串，影响关键信息保留。

因此，本文使用基于TF-IDF的字符串摘要技术，具有以下特点：

- 保留TF-IDF分数高的作为非停止词标记。
- 忽略了候选项中已有的开始与结束标签，使用scikit-learn库中的停止词列表。

实验结果表明，该项优化使Ditto在一个文本密集的数据集上的F1 score从40%提升到了92%。

（切ppt，进入4.5.2）

TF-IDF是一项加权技术，全称为Term Frequency-Inverse Document Frequency。

这项算法需要计算两个值，一个是词频，即TF；另一个是逆文本频率，即IDF。为什么计算词频还不够，还需要额外计算一项IDF呢？因为在文本中总会有很多类似于“的”、“是”、“在”诸如此类的高频但不重要的词。逆文档频率便是为了平衡这种无意义词语的词频现象提出的，本文可以看到在公式里，包含该词的文档数越多，分母越大，计算出的IDF值就越小。分母中的“+1”是为了让分母不为0。

（切ppt，进入4.5.3）

接下来介绍一下数据增强技术。数据增强技术多数是应用在计算机视觉领域，比如对一个图像进行左右翻转、旋转、裁剪等操作。在实体匹配问题下，本文也可以模仿借鉴这种技术，增强本文模型的鲁棒性。本文提出了五种数据增强操作符。一共分为三类：片段级、属性级、条目级。

片段级操作的出现主要是考虑到当多个支持决策的文本出现时，会过于容易的做出决定。比如本文在对如下实体对进行匹配时
$$
\text{[CLS] . . . [VAL] Google LLC . . . [VAL] (866) 246-6453 [SEP] . . .} \\
\text{[VAL] Alphabet inc . . . [VAL] (650) 253-0000 [SEP]}
$$
模型可能仅仅依靠电话号码就得出两个实体不匹配的结果。通过片段级操作，比如删除电话号码，能让模型通过其他信息判断是否两个实体不匹配。属性级的操作动机与此类似，只不过是摆脱对某一个属性的依赖。条目级的操作主要是希望模型不受候选对的输入顺序影响，可以生成两个对称的决策结果。

（切ppt，进入4.5.3）

不像是在图像领域进行数据增强，在实体匹配领域进行数据增强，比如在图像领域中，一只猫的照片左右翻转之后仍然是一只猫。但是在实体匹配领域，一段话重新排序之后可能会造成语义的改变，比如哈利波特中的名场面“tom marvolo riddle”重新排序之后会得到“I am lordvoldemort”，这会导致原来正确的标签变成错误的标签。再比如attr_del 运算符可能会完全删除公司名称，而其余属性可能不包含任何有用的信息来区分这两个条目。

为了解决这项问题，本文利用了混合数据增强（Mix Data Augment，MixDA）技术，选择的算法为MixUp，对原本的数据项与增强后的数据进行凸插值处理，具体过程如图所示。

（讲完过程切ppt，进入5）

# 实验

下面介绍一下实验部分。

（切ppt，进入5.1）

首先介绍一下数据集。

实验一使用的数据是用于评估DeepMatcher的13个公开数据集。分别来自ER Benchmark datasets 与the Magellan data repository。每个数据集都由来自两个相同模式的实体记录表的候选对组成，这些候选对都是从已经进行过分块，并进行了人工标注。Positive rate（即其中相匹配的候选对）从9.4%到25%不等，属性的数量从1到8不等。每个数据集以 3:1:1 的比例分为训练集、验证集和测试集。除此之外，还包含Textual类型数据集，即该数据集中至少有一个属性包含长文本，另外为了衡量模型对噪声的鲁棒性，其中四个数据集为脏数据集，这个脏数据集是通过将原本的数据集通过随机清空属性值并将该属性值附加到另一个随机选择的属性上得来的。

Benchmark2使用WDC产品数据语料库，一共包含2600万条产品报价与描述，为了评价和匹配器的匹配正确率，数据集一共提供了4400个标签，并将候选对分为四类，每一类都有300个匹配的与800个不匹配的候选对。

（切ppt，进入5.2）

在模型对比设置方面，本文设置了1项实验模型，4项对比模型。在这里用 DeepMatcher+（或简称 DM+）表示 DeepER、DeepMatcher 、Magellan中最好的 F1 分数。

这里的Ditto模型是本文实验提出的完整版本的Ditto，保留了三种优化措施（DA,SU,DK）Ditto(DA)版本是仅使用了数据增强（MixDA）与SU，没有DK优化，Ditto(DK)是没有使用数据增强的版本。Baseline使用的是没有优化措施的Ditto。

对于ER-Magellan的13个数据集（除了company数据集），本文发现 RoBERTa 通常可以达到最佳性能。因此，本文在所有数据集的其他 3 个 Ditto 变体（Ditto、Ditto(DA) 和 Ditto(DK)）中默认使用 RoBERTa。company数据集是唯一的例外，本文发现 BERT 模型表现最好。在WDC基准集，由于训练集很大，本文使用DistilBERT以加快训练速度。

之所以设置这么多Ditto对照组，就是为了进行消融研究，下面先简要介绍一下消融研究。

（切ppt，进入5.3）

消融研究最早出现在神经解剖学的研究过程中，ablation本意有去除的意思，人们经常把大脑的某部分破坏然后观察生物的行为有哪些改变。推广到深度学习中，比如为了提升baseline的性能，给它加了两个模块A和B 为了验证AB两个模块是不是真的都有用，你需要做消融研究。 设计实验1：在baseline的基础上加上模块A，看效果。 设计实验2：在baseline的基础上加上模块B，看效果。 设计实验3：在baseline的基础上同时加上模块AB，看效果。 然后结果可能是，实验1和实验2的结果都不如实验3，那么说明AB都是有用的； 然而也有可能你会发现实验1的结果和实验3一样，甚至更好。这就说明你的想法是有问题的，模块B其实并没有起到作用，提升只来自于模块A。本文中设计实验分析Ditto中各项优化措施的有效性。

（切ppt，进入5.4，table 5）

这张表上展示了各个模型在ER-Magellan数据集上的表现。

1. 有优化的Ditto相较于DM+在绝大多数数据集上有明显提升，没有优化的Ditto即baseline模型也达到了与DM+类似的效果。
2. Ditto在13个数据集下表现均优于DeepMatcher+，最高多出31%，而baseline在12种情况下优于DeepMatcher+，仅在company数据集下表现较差。
3. Ditto在小型的数据集上表现的更好。在最小的七个数据集上平均改进为15.6%，而在其他数据集上平均改进1.48%，七个最小的数据集就是红框标出来的七个数据集。
4. 在4个脏数据集上，Ditto展现出了更好的抗噪声能力，Ditto 的性能平均下降仅为 0.57，而 DM+ 的性能下降了 8.21。

在ER-Magellan数据集（不包括company）中，与DeepMatcher+相比，baseline的平均改进为3.49，占完整Ditto改进的58%。

虽然DeepMatcher+和baseline（基本上是微调DistilBERT）在结构化数据集上不相上下，但baseline在所有的Dirty数据集和Abt-Buy数据集上表现得更好。这证实了本文的观点，即语言理解能力是Ditto相对于现有EM解决方案的一个关键优势。company数据集是一个特例，因为公司文章的长度（平均 3,123 个单词）远大于最大序列长度 256。SU 优化将该数据集的 F1 分数从 41% 提高到 93% 以上。

（切ppt，进入5.4，table 6）

这张表上展示了DM模型和Ditto模型在WDC数据集上的表现。

当使用所有215k的训练数据时，Ditto获得了最高的94.08的F1分数，比之前的最佳结果高出了3.92。与本文在Benchmark 1中发现的情况类似，在训练实例较少的情况下，改进的程度更高。结果还显示，Ditto比DeepMatcher的标签效率更高。例如，当只使用1/2的数据（Large）时，Ditto已经比拥有所有训练数据（xLarge）的DeepMatcher高出2.89。当只使用1/8的数据（Medium）时，接近DeepMatcher在使用1/2的数据（Large）时的F1分数。唯一的例外是在shoes这个类别。这可能是由于训练集和测试集之间的positive标签比率差距很大（根据表4，9.76%对27.27%）。

在ER-Magellan数据集上，DK的优化更为有效。与baseline相比，Ditto(DK)的改进平均为1.98，在Beer数据集上的改进高达9.67，而在WDC数据集上的改进平均只有0.22。本文检查了span类型的输出，发现只有66.2%的条目对有相同类型的span。这是由于当前的 NER 模块没有使用正确的类型提取与产品相关的span。

作者觉得如果本文使用在产品领域训练的NER模型，DK会更有效。DA在两个数据集上都很有效，在WDC数据集上表现更明显。在两个数据集上，完整的Ditto的平均F1得分比Ditto(DK)分别提高了1.39和2.53。

（切ppt，进入5.5，table 8）

本文还将Ditto应用于一个现实任务：employer matching。给定雇主记录的两个表 A 和 B，目标是为表 B 中的每条记录找到表 A 中代表同一雇主的记录。两个表都有 6 个属性：name、addr、city、state、zipcode 和 phone。这张表展示了数据集的数据量，可以看到即使在去重之后，表A仍然具有70多万条数据量，表B有6万多条数据量，远远大于Benchmark中数据集的数据量。

本文设计的第一个分块方法是只匹配具有相同邮政编码的公司。但是，由于表 A 中 60% 的记录没有邮政编码属性，并且一些大型雇主有多个站点，本文使用第二种分块方法，通过计算name 和 addr 属性的 TF-IDF 余弦相似度，为表 B 中的每条记录返回 A 中最相似的前 20 条记录。本文使用这两种方法的并集作为进行分块，它产生了 1000 万个候选对，是个十分惊人的数量。

同时本次实验从两种分块方法中各sample & label 10000个实体对，共打标签了20000个实体对。并且尽量采样高相似度的实体对进行训练，这样能够增强模型的鲁棒性。本次采样中的正类占比为39%，同样按 3:1:1 的比例将标记对分成训练集、验证集和测试集。

（切ppt，进入5.5，figure 5）

本文观察到addr和phone都是有用的匹配信号。因此，本文指定了一个简单的识别器，它标记 addr 属性中的第一个数字字符串和 phone 属性的最后 4 位数字。由于本文希望训练后的模型对大量缺失值具有鲁棒性，因此本文选择 attr_del 运算符进行数据增强。

图 5 中展示了各个模型在这项任务中的表现。可以看到在使用所有训练数据时，Ditto 的 F1 得分最高，为 96.53。 Ditto 在 F1 中的表现优于 DeepMatcher (DM)，并且即使使用 MixDA，它在不同的训练集大小上比 DeepMatcher 训练得更快。

（切ppt，进入5.6）

本实验的最后还提出了一种改进的分块方法。

在将训练好的模型应用于所有候选对之前，本文可以使用标记数据来改进basic blocking方法。利用 Sentence-BERT,将其与向量相似性搜索结合使用，以快速找到可能匹配的记录对。本文可以通过只测试那些高余弦相似度对来大大减少匹配时间。

使用这种技术，整个 EM 过程加快了 3.8 倍（1.69小时 vs. 6.49小时）。

这张表展示了每个模块的运行时间。高级分块包括两个步骤：使用 Sentence-BERT计算每个记录的向量表示，以及通过分块矩阵乘法 进行相似性搜索。使用高级分块方法，本文只根据模型将每条记录与前 10 个最相似的记录进行匹配。

（切ppt，进入6）

# 评价

下面对本文进行一个简要的评价

（切ppt，进入6.1）

Ditto作为第一个公开发表的基于预训练模型的实体匹配模型，主要有以下三个优点。

1. 模型简单，使用预训练模型作为基础，通过微调便能得到不错的效果。
2. 开发了三种优化技术，通过注入领域知识、长字符摘要技术和数据增强技术增加训练数据来进一步提高了匹配能力。
3. 在三个benchmark数据集和现实大规模实体匹配任务上进行了实验。实验证明，Ditto在绝大多数的数据集上都优于以前的EM解决方案。

（切ppt，进入6.2）

Ditto的缺点也很明显：

1. 如果达到好的效果需要大量标注好的实体对，人力成本太高。例如，案例研究需要 6k 示例才能达到 95% 的 F1分数，如果要表现得更好甚至要标记上万对实体对。
2. Ditto 中的 language model 是在通用英文文本语料库上进行预训练的，因此无法很好地捕捉具有大量数字数据或特定领域的 EM 任务。
3. 可解释性不足。

（切ppt，进入6.3）

1. 对于特定领域的任务，一个潜在的解决方案是利用专门的 language model，例如使用分别在科学和生物学语料库上训练的SciBERT或 BioBERT。
2. 对于数字类型数据，一个解决方案是借助将数字特征与文本特征相结合的混合神经网络。

2022年，Jianhong Tu和范举等在《Domain Adaptation for Deep Entity Resolution》中提出DADER模型。借助迁移学习，对于给定的任意数据集不需要标注出训练集，仅利⽤现有的⼀些公开的已标注的数据集来训练模型从⽽实现在⽬标数据集上的良好性能。
